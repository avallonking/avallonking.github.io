<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Grasp information of multiple papers from PubMed and arXiv</title>
  <meta name="description" content="Researchers often need to search for a lot of literatures. Sometimes, they want to collect the information of those literatures and classified them into diff...">
  <link href='https://fonts.googleapis.com/css?family=PT+Sans:400,700,400italic,700italic|Source+Sans+Pro:400,700,200,300|Josefin+Sans:400,600,700,300' rel='stylesheet' type='text/css'>
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/style.css">
  <link rel="canonical" href="http://localhost:4000/scitech/2018/01/14/scitech.html">
  <link rel="alternate" type="application/rss+xml" title="Avallon Island" href="http://localhost:4000/feed.xml">
</head>


  <body class=" light  ">

    
<div class="wrapper">
  <center> <a href="/index.html"><div class="site-title">   Avallon Island </div></a></center>
</div>
<div class="wrapper site-description">
<center>  Albert Lee's blogs about discoveries in science, technology and life </center>
</div>
<div class="wrapper">
  <div class="trigger site-navigation">
    <a class="page-link" href="http://localhost:4000">HOME</a>

    
    

    <span class="exclamationMark">/</span><a class="page-link" href="/about/">About</a>
    
    
    

    <span class="exclamationMark">/</span><a class="page-link" href="/software/">Software</a>
    
    
    
    
    
    
    

    <span class="exclamationMark">/</span><a class="page-link" href="/scitech/">Sci-Tech</a>
    
    
    
    
    
    
  </div>
</div>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
    <h1 class="post-title" itemprop="name headline">Grasp information of multiple papers from PubMed and arXiv</h1>
  <center>  <p class="post-meta"><time datetime="2018-01-14T00:40:31-08:00" itemprop="datePublished">Jan 14, 2018</time></p>
    
   </center>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>Researchers often need to search for a lot of literatures. Sometimes, they want to collect the information of those literatures and classified them into different categories. Obviously, it is very inconvenient and inefficient to do this manually. However, we can automize this process with API. Here, I introduce this method with examples.</p>

<p>Basically, <a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a> is an interface providing developers with information access. We can use API to do the same searching using the same keywords and parameters as what we do on the webpage, and API can give us the results in <a href="https://en.wikipedia.org/wiki/XML">xml</a> format. Therefore, to do this task, we need 2 Python packages, <a href="https://en.wikipedia.org/wiki/XML">Requests</a> to access APIs and <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a> to process XML.</p>
<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># install requests and bs4 (Beautiful Soup)</span>
conda install requests beautifulsoup4

<span class="c"># if you use pip</span>
pip install requests beautifulsoup4
</code></pre></div></div>

<h3 id="pubmed-api">PubMed API</h3>
<p>At first, let’s explore PubMed API. Its detailed documentation can be found <a href="https://www.ncbi.nlm.nih.gov/books/NBK25497/">here</a>. This time, I want to talk about the usage two of PubMed APIs: <em>esearch.fcgi?</em> and <em>efetch.fcgi?</em>. <em>esearch.fcgi?</em> responds to a text query with a list of literature IDs, while <em>efetch.fcgi?</em> responds to a list of IDs in a given database with corresponding data records.</p>

<p>Step 1, use <em>esearch.fcgi?</em> to get literatures IDs.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="c"># we need to tell the API our query terms, database (PubMed this time) and how maximum </span>
<span class="c"># records we want to see</span>
<span class="k">def</span> <span class="nf">get_id</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="s">'pubmed'</span><span class="p">,</span> <span class="n">max_record</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
  <span class="c"># URL of the API</span>
  <span class="n">search_url</span> <span class="o">=</span> <span class="s">'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'</span>
  <span class="c"># parameters for this API</span>
  <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">'term'</span><span class="p">:</span> <span class="n">query</span><span class="p">,</span> <span class="s">'db'</span><span class="p">:</span> <span class="n">db</span><span class="p">,</span> <span class="s">'retmax'</span><span class="p">:</span> <span class="n">max_record</span><span class="p">}</span>
  <span class="c"># get the data with requests.get</span>
  <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">search_url</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">)</span>
  <span class="c"># since results are in XML format, use beautiful soup to process it</span>
  <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'xml'</span><span class="p">)</span>
  <span class="c"># extract IDs</span>
  <span class="n">id_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">IdList</span><span class="o">.</span><span class="n">stripped_strings</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">id_list</span>
</code></pre></div></div>

<p>Step 2, use <em>efetch.fcgi?</em> to get literatures data with previous IDs.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># to use this API, we need to provide a list of IDs, database (PubMed again), output </span>
<span class="c"># results format (XML) and maximum number of records</span>
<span class="k">def</span> <span class="nf">fetch_info</span><span class="p">(</span><span class="n">id_list</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="s">'pubmed'</span><span class="p">,</span> <span class="n">retmode</span> <span class="o">=</span> <span class="s">'xml'</span><span class="p">,</span> <span class="n">max_record</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
  <span class="c"># similar with above</span>
  <span class="n">fetch_url</span> <span class="o">=</span> <span class="s">'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi'</span>
  <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">'db'</span><span class="p">:</span> <span class="n">db</span><span class="p">,</span> <span class="s">'id'</span><span class="p">:</span> <span class="n">ids</span><span class="p">,</span> <span class="s">'retmode'</span><span class="p">:</span> <span class="n">retmode</span><span class="p">,</span> <span class="s">'retmax'</span><span class="p">:</span> <span class="n">max_record</span><span class="p">}</span>
  <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">records_url</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">)</span>
  <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'xml'</span><span class="p">)</span>
  <span class="c"># results information are labeled with various tags, simply check with print(soup.text)</span>

  <span class="c"># get articles information</span>
  <span class="n">article_info</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'PubmedArticle'</span><span class="p">)</span>
  <span class="c"># for each article, extract its title, and publication year. You can also extract </span>
  <span class="c"># other information using different tags</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">article_info</span><span class="p">:</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">ArticleTitle</span><span class="o">.</span><span class="n">text</span>

    <span class="k">try</span><span class="p">:</span>
      <span class="n">pub_year</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">PubDate</span><span class="o">.</span><span class="n">Year</span><span class="o">.</span><span class="n">text</span>
    <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
      <span class="n">pub_year</span> <span class="o">=</span> <span class="s">'Unknown'</span>

    <span class="c"># print out the results</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Title: '</span> <span class="o">+</span> <span class="n">title</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Year: '</span> <span class="o">+</span> <span class="n">pub_year</span><span class="p">)</span>
</code></pre></div></div>

<p>Finally, simply put them together, say, let’s search for papers about deep learning and cancer.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">query</span> <span class="o">=</span> <span class="s">'deep learning cancer'</span>
<span class="n">id_list</span> <span class="o">=</span> <span class="n">get_id</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="n">fetch_info</span><span class="p">(</span><span class="n">id_list</span><span class="p">)</span>
<span class="c"># then it outputs results to the console. And we can save them into a file for follow-up</span>
<span class="c"># analysis</span>
</code></pre></div></div>

<h3 id="arxiv-api">arXiv API</h3>
<p>This principle is totally the same to <a href="https://arxiv.org/help/api/index#python_simple_example">arXiv API</a>. arXiv API is even more simpler than PubMed API because it just needs one API.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fetch_info_arxiv</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">max_record</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">):</span>
  <span class="n">url</span> <span class="o">=</span> <span class="s">'http://export.arxiv.org/api/query'</span>
  <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s">'search_query'</span><span class="p">:</span> <span class="n">query</span><span class="p">,</span> <span class="s">'max_results'</span><span class="p">:</span> <span class="n">max_record</span><span class="p">}</span>
  <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">)</span>
  <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'xml'</span><span class="p">)</span>
  <span class="n">article_info</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'entry'</span><span class="p">)</span>
  <span class="c"># extract title, authors, and publication year for each article</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">article_info</span><span class="p">:</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">text</span>

    <span class="n">authors</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">author_list</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'author'</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">author_list</span><span class="p">:</span>
        <span class="n">author</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
        <span class="n">authors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">author</span><span class="p">)</span>
    <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
      <span class="k">pass</span>
    
    <span class="c"># pub_date = 'YYYY-MM-DDThh:mm:ssZ'</span>
    <span class="n">pub_date</span> <span class="o">=</span> <span class="n">i</span><span class="o">.</span><span class="n">published</span><span class="o">.</span><span class="n">text</span>
    <span class="n">pub_year</span> <span class="o">=</span> <span class="n">pub_date</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'-'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c"># print out the results</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Title: '</span> <span class="o">+</span> <span class="n">title</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Authors: '</span> <span class="o">+</span> <span class="s">', '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">authors</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Year: '</span> <span class="o">+</span> <span class="n">pub_year</span><span class="p">)</span>

<span class="c"># search for deep learning</span>
<span class="n">fetch_info_arxiv</span><span class="p">(</span><span class="s">'deep learning'</span><span class="p">)</span>
</code></pre></div></div>

<p>In conclusion, API allows us to fetch much information with a few lines of codes, so it is very useful and easy to learn. Besides, APIs share the same working principles. Unfortnately, not every website has APIs. For example, bioRxiv does not have any APIs. But, at least, we have moved forward.</p>

  </div>

  <footer class="postNavigation">
  
  
  </footer>


</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading small-site-title">Avallon Island</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list footer-content">
          <li>Powered By <a href="http://github.com/hemangsk/Gravity">Gravity</a></li>
          <li>Made with <i class="fa fa-heart"></i> on <a href="http://jekyllrb.com"><span>{ { Jekyll } }</a></span></li>


        </ul>
      </div>

      <div class="footer-col footer-col-2 footer-content">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/avallonking"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">avallonking</span></a>

          </li>
          

          

          
          <li>
            <a href="https://www.linkedin.com/in/jiajinli"><span class="icon icon--twitter"><?xml version="1.0" encoding="iso-8859-1"?>
<!-- Generator: Adobe Illustrator 16.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" id="Capa_1" x="0px" y="0px" width="512px" height="512px" viewBox="0 0 430.117 430.117" style="enable-background:new 0 0 430.117 430.117;" xml:space="preserve">
<g>
	<path id="LinkedIn" d="M430.117,261.543V420.56h-92.188V272.193c0-37.271-13.334-62.707-46.703-62.707   c-25.473,0-40.632,17.142-47.301,33.724c-2.432,5.928-3.058,14.179-3.058,22.477V420.56h-92.219c0,0,1.242-251.285,0-277.32h92.21   v39.309c-0.187,0.294-0.43,0.611-0.606,0.896h0.606v-0.896c12.251-18.869,34.13-45.824,83.102-45.824   C384.633,136.724,430.117,176.361,430.117,261.543z M52.183,9.558C20.635,9.558,0,30.251,0,57.463   c0,26.619,20.038,47.94,50.959,47.94h0.616c32.159,0,52.159-21.317,52.159-47.94C103.128,30.251,83.734,9.558,52.183,9.558z    M5.477,420.56h92.184v-277.32H5.477V420.56z" fill="#a1a1a1"/>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
<g>
</g>
</svg>
</span><span class="username">jiajinli</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3 site-description">
        <p>Albert Lee's blogs about discoveries in science, technology and life</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
